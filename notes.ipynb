{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n a machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu√© es machine learning y su historia\n",
    "\n",
    "- Modelos de ML **encuentran patrones en datos para resolver problemas.**\n",
    "- Los modelos aprenden patrones de los features.\n",
    "- Features son descriptores de tus datos que pueden ayudarte en la tarea que quieres resolver \n",
    "- **Machine learning** (ML) es un campo en crecimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework de ciencia de datos: herramientas para machine learning\n",
    "\n",
    "### Terminolog√≠a para ciencias de datos:\n",
    "- Data: unidades de informaci√≥n o ‚Äúhechos‚Äù de observaciones.\n",
    "- Features: tipos de informaci√≥n acerca de tus observaciones. (ej: gender, height, etc).\n",
    "- Row: observaciones individuales o muestras.\n",
    "- Columns: features que describen tus observaciones.\n",
    "- Outlier: punto(s) de datos o data point(s) que se comportan de forma extra√±a.\n",
    "- Pre-processing: preparar datos para su uso en un modelo de machine learning\n",
    "- ETL pipeline: framework de data science para extraer, transformar y cargar.\n",
    "\n",
    "\n",
    "### Tipos de datos\n",
    "- Numerical: su feature es un n√∫mero de tipo entero o flotante\n",
    "- Categorical: sus features representan una clase o tipo; usualmente representan como un mapeo de n√∫meros o un \"one-hot\" vector.\n",
    "- Image: su feature representa una imagen\n",
    "- Text: su feature es en la forma de texto, sea corto (como Twitter) o largo (como en noticias).\n",
    "- NaN: su feature es desconocido o perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de modelos de machine learning\n",
    "\n",
    "<img src='https://static.platzi.com/media/user_upload/MLAlgorithms-8dbc096a-dd73-48ce-bef9-42a56f2e0639.jpg' width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje supervisado\n",
    "\n",
    "El modelo obtiene features de entrada y salida. Hay un target a predecir.\n",
    "\n",
    "- **Regresi√≥n:** Target output es num√©rico. (advertising popularity prediction, estimaci√≥n de esperanza de vida, pron√≥stico de temperatura, pron√≥stico de mercado)\n",
    "\n",
    "- **Clasificaci√≥n:** Target output es etiqueta. (Clasificaci√≥n de im√°genes, retenci√≥n de clientes, detecci√≥n de fraude de identidad, diagn√≥sticos)\n",
    "\n",
    "### Aprendizaje no supervisado\n",
    "\n",
    "Objetivo desconocido, queremos encontrar estructura y grupos dentro de los datos.\n",
    "\n",
    "- Clustering: Queremos encontrar grupos en los datos. (Segmentaci√≥n de clientes, marketing dirigido, sistema de recomendaciones)\n",
    "\n",
    "- Dimensionality reduction: Queremos encontrar que features de entrada en los datos son de ayuda. (Compresi√≥n significativa, visualizaci√≥n de big data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casos de uso algoritmos de Machine Learnign\n",
    "- Aprendizaje supervisado\n",
    "    - Clasificaci√≥n\n",
    "        - Regresi√≥n log√≠stica\n",
    "        - Random forest\n",
    "    - Regresi√≥n\n",
    "        - Regresi√≥n lineal\n",
    "- Aprendizaje no supervisado\n",
    "    - Dimension reduction:\n",
    "        - PCA (principal component analisys) \n",
    "        -  T-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "    - Clustering: \n",
    "        - K-means\n",
    "        - Hierarchical clustering\n",
    "\n",
    "### Resumen\n",
    "\n",
    "- Algoritmos de machine learning generalmente son supervisados o no supervisados\n",
    "- Algoritmos supervisados predicen un target. Pueden ser regresi√≥n o clasificaci√≥n\n",
    "- Algoritmos no supervisados predicen patrones o estructura en los datos. Generalmente, son de clustering o dimensionality reduction\n",
    "\n",
    "[Reto](./reto_1_procesando_un_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos simples de machine learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La ‚Äúreceta‚Äù para aplicar algoritmos de machine learning\n",
    "\n",
    "1. Proceso de decisi√≥n: como los modelos hacen una predicci√≥n, o retornan una repuesta, usando los par√°metros\n",
    "1. Funci√≥n de error/coste\" como evaluar si los par√°metros en el modelo generan buenas predicciones.\n",
    "1. Regla de actualizaci√≥n: como mejorar los par√°metros para hacer mejores predicciones (utilizando optimizaciones num√©ricas).\n",
    "\n",
    "\n",
    "#### Normalizar tus datos num√©ricos\n",
    "\n",
    "**Para cada columna de tu dataset con valores num√©ricos:**\n",
    "1. Calcular el promedio de tus datos ($\\mu$).\n",
    "1. Calcular la desviaci√≥n est√°ndar ($\\sigma$) de tus datos.\n",
    "1. Para cada punto de datos, realizar: $\\displaystyle{\\hat{x_i}=\\frac{x_i-\\mu}{\\sigma}}$\n",
    "\n",
    "#### Preparar tus datos para modelos\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/b/bb/ML_dataset_training_validation_test_sets.png' width=500>\n",
    "\n",
    "- **Training**: (60-80%) datos de los que el modelo aprende patrones.\n",
    "- **Validation**: (0-20%) datos que empleas para verificar que el modelo aprende.\n",
    "- **Testiting**: (0-20%) datos que se apartan para revisar si el modelo fue exitoso al predecir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n lineal\n",
    "\n",
    "### Bases\n",
    "\n",
    "<img src='https://www.addlink.es/images/productos/minitab/OrdenModelo.png'>\n",
    "\n",
    "### Par√°metros\n",
    "\n",
    "\n",
    "Diferentes par√°metros cambian lo que pensamos de la relaci√≥n entre input features ($x$) y el output target ($y_{pred}$).\n",
    "\n",
    "$y_{pred}=w_1.x+w_0$\n",
    "\n",
    "$w_1$ = un cambio en $\"x\"$ resulta un cambio en $\"y\"$\n",
    "\n",
    "$w_0$ = el valor de $\"y\"$ si $\"x\"$ es 0.\n",
    "\n",
    "### Funci√≥n de coste\n",
    "\n",
    "\n",
    "**Mean-square Error (MSE) Loss:**\n",
    "\n",
    "El costo ($\\displaystyle{\\epsilon}$) es la diferencia entre el valor del target $(y_i)$ y el valor predicho de nuestra l√≠nea $(y_pred)$.\n",
    "\n",
    "$J(w,w_0)= \\frac{1}{N} \\sum \\limits_{i=1}^{N} (y_i - y_{i,pred})^2$\n",
    "\n",
    "<img src='https://slideplayer.com/slide/3274418/11/images/6/Measuring+error+Error+or+residual+Observation+Prediction.jpg'>\n",
    "\n",
    "### Regla de actualizaci√≥n\n",
    "\n",
    "Queremos minimizar la distancia $y_{i,pred}$ sobre cada punto de datos en entrenamiento\n",
    "\n",
    "Cambiamos $w_0$ y $w_1$ hasta encontrar una suma de distancia menor.\n",
    "\n",
    "$Update Rule = min\\;J(w_0,w_1)$\n",
    "\n",
    "### Rendimiento\n",
    "\n",
    "$MSE$ y $R^2$ ayudan a identificar la fortaleza de la relaci√≥n entre features de entrada y de salida.\n",
    "\n",
    "<img src='https://www.maximaformacion.es/wp-content/uploads/2021/07/Que-es-la-correlacion_valores-del-coeficiente.png'> \n",
    "\n",
    "### Resumen\n",
    "\n",
    "**Proceso de decisi√≥n:**\n",
    "> Una funci√≥n para predecir el target de salida basada en featuares de entrada.\n",
    "\n",
    "$y_{pred}=w_0+w_1.x_1+w_2.x_2+\\cdots+w_n.x_n$\n",
    "\n",
    "**Funci√≥n de error/coste:**\n",
    "> El promedio de que tan bien se predice el target.\n",
    "\n",
    "$J(w,w_0)= \\frac{1}{N} \\sum \\limits_{i=1}^{N} (y_i - y_{i,pred})^2$\n",
    "\n",
    "**Regla de actualizaci√≥n:**\n",
    "> En cuenta valores $w,w_0$ que mejoren las predicciones.\n",
    "\n",
    "$\\min\\;J(w_0,w_1,\\cdots,w_n)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n log√≠stica\n",
    "\n",
    "### Proceso de decisi√≥n:\n",
    "> Probabilidad de que un estudiante pase $y=1$ \n",
    "\n",
    "$\\displaystyle p{Pass}=\\displaystyle\\frac{\\exp(w_0+w_1.x_1+\\cdots+w_n.x_n)}{1+\\exp(w_0+w_1.x_1+\\cdots+w_n.x_n)}$\n",
    "\n",
    "### Funci√≥n de error/coste:\n",
    "> Promedio de que tan bien se predice que un estudiante pasa\n",
    "\n",
    "$J(w,w_0)= -\\frac{1}{N} \\sum \\limits_{i=1}^{N} y_i\\log(p_{pass}) + (1-y_1)\\log(1-p_{pass})$\n",
    "\n",
    "### Regla de actualizaci√≥n:\n",
    "> Encuentra valores w y w_0 que mejor predicen esta probabilidad\n",
    "\n",
    "$\\min\\;J(w_0,w_1,\\cdots,w_n)$\n",
    "\n",
    "### Rendimiento\n",
    "\n",
    "Se aplica una matriz de confusi√≥n\n",
    "\n",
    "- [Precision, Recall, F1, Accuracy en clasificaci√≥n](https://www.iartificial.net/precision-recall-f1-accuracy-en-clasificacion/)\n",
    "- [Clasificaci√≥n en MACHINE LEARNING R√ÅPIDO! - (Explicado en 7 MINUTOS) ü¶æ](https://www.youtube.com/watch?v=8-nt3Urok4E)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √Årboles de decisi√≥n\n",
    "\n",
    "### Bases\n",
    "\n",
    "<img src='https://cdn-cashy-static-assets.lucidchart.com/lucidspark/marketing/blog/2020Q4/decision-tree/Decision-tree.png' width=700>\n",
    "\n",
    "**Nodo de decisi√≥n (Chance node)**: Parte los datos en subconjuntos de datos.\n",
    "\n",
    "**Nodo hoja (Outcome)**: La etiqueta de asignaci√≥n o resultado del labeling.\n",
    "\n",
    "Los conjuntos permiten 'votar' por la respuesta correcta.\n",
    "\n",
    "<img src='https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/example-of-random-forest-classifier.png' width=600>\n",
    "\n",
    "### Par√°metros\n",
    "\n",
    "**N√∫mero de √°rboles:** m√°s √°rboles, menor variaci√≥n, pero m√°s computo.\n",
    "\n",
    "**Max Features:** El n√∫mero de features usados para partir (split).\n",
    "\n",
    "**Max depth:** El n√∫mero de niveles del √°rbol de decisi√≥n.\n",
    "\n",
    "**$N_{split}$ = Min samples split:** N√∫mero de data points que un nodo debe tener antes de dividirse.\n",
    "\n",
    "**$n_{min}$ = Min samples leaf:** El m√≠nimo n√∫mero de muestras requeridas para estar en una hoja (leaf).\n",
    "\n",
    "### Funci√≥n de coste y regla de actualizaci√≥n\n",
    "\n",
    "Funci√≥n de coste: para un feature seleccionado encuentra el mejor splot-point (punto de separaci√≥n) y separa los datos en nodos m√°s peque√±os\n",
    "\n",
    "Regla de actualizaci√≥n: si el nodo hoja tiene m√°s de $n_{min}$ puntos de datos, repite la funci√≥n de coste, si no para.\n",
    "\n",
    "### Rendimiento\n",
    "\n",
    "- Se pueden utilizar m√©tricas de **clasificaci√≥n** o **regresi√≥n** para evaluar que tan bueno es el modelo.\n",
    "\n",
    "**Clasificaci√≥n:** Confusion matrix o matriz de confusi√≥n\\\n",
    "**Regresi√≥n:** MSE / $R^2$\n",
    "\n",
    "### Repaso\n",
    "\n",
    "- **Proceso de decisi√≥n:**\\\n",
    "De un subset de features aleatorios de tus datos, elige un feature. Divide tus datos\n",
    "\n",
    "- Funci√≥n **de error/coste:**\\\n",
    "Usando Gini o criterio de entrop√≠a para encontrar el mejor umbral para dividir tus datos.\n",
    "\n",
    "- **Regla de actualizaci√≥n:**\\\n",
    "Si los nodos hoja no tienen $n_{min}$ puntos de datos, repite el proceso.\n",
    "\n",
    "Material extra:\n",
    "\n",
    "- [Video: Clasificaci√≥n con √Årboles de Decisi√≥n ¬°EN 15 MINUTOS!](https://www.youtube.com/watch?v=kqaLlte6P6o)\n",
    "- [Lectura: Introduction to Random Forest in Machine Learning](https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/#:~:text=A%20random%20forest%20is%20a%20machine%20learning%20technique%20that's%20used,consists%20of%20many%20decision%20trees.)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos no supervisados (K-Means clustering)\n",
    "\n",
    "### Bases\n",
    "\n",
    "**K-Means** es un m√©todo de agrupamiento, que tiene como objetivo la partici√≥n de un conjunto de n observaciones en k grupos, en el que cada observaci√≥n pertenece al grupo cuyo valor medio es m√°s cercano. Es un m√©todo utilizado en miner√≠a de datos.\n",
    "\n",
    "El **centroide** es un punto representativo de cada cl√∫ster. El algoritmo K-means asigna cada punto de datos entrante a uno de los cl√∫steres, minimizando la suma en el cl√∫ster de cuadrados. Cuando procesa los datos de entrenamiento, el algoritmo K-means comienza con un conjunto inicial de centroides elegidos al azar\n",
    "\n",
    "\n",
    "<img src='https://datascience.eu/wp-content/uploads/2019/12/Screenshot-2020-10-17-at-13.30.08-978x652.png' width=700>\n",
    "\n",
    "### Par√°metros\n",
    "\n",
    "**\"K\"** se refiere al n√∫mero de grupos que piensas existen en los datos. Cuando tengas distinto n√∫mero de grupos podr√°s apreciar resultados distintos dentro de las agrupaciones\n",
    "\n",
    "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_bisect_kmeans_001.png' width=900>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funci√≥n de coste\n",
    "\n",
    "A trav√©s de la funci√≥n de coste intentamos optimizar el algoritmo de K-means, lo cual el algoritmo intenta averiguar es como establecer los centroides para que los puntos est√©n m√°s cerca de ellos \n",
    "\n",
    "$\n",
    "\\displaystyle J(c^1,\\cdots,c^{K})  = \\sum^{K}_{j=1} \\sum_{x \\in S_{j}} \\left\\| \\mathbf x_i^j - \\boldsymbol c^{i} \\right\\|^2 \n",
    "$\n",
    "\n",
    "$\n",
    "\\displaystyle  \\sum^{K}_{j=1}\\;\\longrightarrow\\;\\displaystyle  \\text{Donde K es igual a la suma sobre todos los cl√∫sters}\n",
    "$\n",
    "\n",
    "$\n",
    "\\displaystyle  \\sum_{x \\in S_{j}}\\;\\longrightarrow\\;\\displaystyle  \\text{Suma todos los puntos de datos en un cl√∫ster }j\n",
    "$\n",
    "\n",
    "$\n",
    "\\displaystyle  x_i^j\\;\\longrightarrow\\;\\displaystyle  \\text{Posici√≥n de un } i^{th} \\text{ punto de datos en el cl√∫ster } j\n",
    "$\n",
    "\n",
    "$\n",
    "\\displaystyle  c^j\\;\\longrightarrow\\;\\displaystyle  \\text{Posici√≥n del centroide para el cl√∫ster } j\n",
    "$\n",
    "\n",
    "$\n",
    "\\displaystyle  \\left\\| \\mathbf x_i^j - \\boldsymbol c^{i} \\right\\|^2 \\;\\longrightarrow\\;\\displaystyle  \\text{Funci√≥n de distancia Euclidiana}\n",
    "$\n",
    "\n",
    "1. Asigna cada punto de datos en un cl√∫ster.\n",
    "1. Calcula los centroides como el promedio de los puntos de datos.\n",
    "\n",
    "- [K-means clustering (part 1)](https://www.youtube.com/watch?v=0MQEt10e4NM)\n",
    "- [K-means clustering (part 2)](https://www.youtube.com/watch?v=4shfFAArxSc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regla de actualizaci√≥n\n",
    "\n",
    "<img src='https://static.platzi.com/media/user_upload/Captura%20de%20Pantalla%202022-10-14%20a%20la%28s%29%2017.36.19-decd566b-8ad0-4896-811d-872ecf58cdb7.jpg' width=700>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendimiento\n",
    "\n",
    "**Para 1 solo modelo**\n",
    "\n",
    "**Inertia:** que tan cerca est√°n los puntos de datos al centroide. Este n√∫mero se necesita peque√±o.\n",
    "\n",
    "**Silhoueete score:** que tan lejanos son los cl√∫sters, de [-1,1]. Este n√∫mero debe ser cercano al 1.\n",
    "\n",
    "**Elbow method:** utiliza la distancia media de las observaciones a su centroide. Es decir, se fija en las distancias intra-cluster. Cuanto m√°s grande es el n√∫mero de cl√∫sters k, la varianza intra-cluster tiende a disminuir\n",
    "\n",
    "<img src='https://i2.wp.com/www.aprendemachinelearning.com/wp-content/uploads/2018/03/ejemplo-elbow.png?resize=768%2C422' width=400>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso\n",
    "\n",
    "**Proceso de decisi√≥n:**\n",
    "\n",
    "- **Calcular** la distancia de cada punto de datos a cada centroide.\n",
    "- **Asignar cada** punto de datos al centroide m√°s cercano.\n",
    "- **Calcular** los nuevos centroides promediando los puntos de datos asignados al cl√∫ster.\n",
    "\n",
    "**Funci√≥n de coste\\error:**\n",
    "\n",
    "Minimizar las distancia de los puntos de datos a los cl√∫ster\n",
    "$\n",
    "\\displaystyle J(c^1,\\cdots,c^{K})  = \\sum^{K}_{j=1} \\sum_{x \\in S_{j}} \\left\\| \\mathbf x_i^j - \\boldsymbol c^{i} \\right\\|^2 \n",
    "$\n",
    "\n",
    "**Regla de actualizaci√≥n:**\n",
    "\n",
    "Repite el proceso de decisi√≥n hasta que los puntos de datos asignados a cada cl√∫ster sean los mismos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reto: aplicar machine learning al dataset Iris\n",
    "\n",
    "Queremos identificar especies de plantas con 4 features:\n",
    "\n",
    "Longitud del s√©palo, ancho del s√©palo, longitud del p√©talo, ancho del p√©talo.\n",
    "\n",
    "[Reto modelo K-Means](./reto2_modelos_ml.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## C√≥mo funcionan las redes neuronales\n",
    "\n",
    "Una red neuronal es un modelo que usa neuronas y conexiones entre ellos para hacer predicciones.\n",
    "\n",
    "Son usadas usualmente para aprendizaje supervisado.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Colored_neural_network_es.svg/300px-Colored_neural_network_es.svg.png'>\n",
    "\n",
    "Cada unidad oculta recibe una combinaci√≥n lineal de todas las entradas.\n",
    "\n",
    "Para la misma entrada existen diferentes pesos dependiendo de cu√°l unidad oculta este adjunta. Estos pesos pueden ser distintos.\n",
    "\n",
    "### Capa de entrada conectada con m√∫ltiples unidades ocultas\n",
    "\n",
    "**Ejemplo:** $W_{2,3}$ El peso de la segunda entrada a la tercera unidad\n",
    "\n",
    "\n",
    "### Hidden units perform a function\n",
    "\n",
    "La unidad oculta ejecuta una funci√≥n en la combinaci√≥n lineal $(g_1(X))$.\\\n",
    "Esta funci√≥n es una **funci√≥n de activaci√≥n**.\n",
    "\n",
    "$$g_1(X) \\rightarrow h_1 \\rightarrow h_1(X)$$\n",
    "\n",
    "$$h_1(X)=f_1 (g_1(X))$$\n",
    "\n",
    "$$\\underbrace{f_1}_{\\text{Funci√≥n de activaci√≥n}} \\;\\;\\;\\;\\;\\; \\underbrace{(g_1(X))}_{\\text{Combinaci√≥n lineal de nodos de la capa anterior}}$$\n",
    "\n",
    "### Tipos de funci√≥n de activaci√≥n de capas ocultas\n",
    "\n",
    "Funci√≥n de activaci√≥n \"pasa\" una se√±al.\n",
    "\n",
    "- [**ReLu**](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n",
    "- [**Sigmoid**](https://en.wikipedia.org/wiki/Sigmoid_function)\n",
    "- [**Tanh**](https://en.wikipedia.org/wiki/Hyperbolic_functions#Tanh)\n",
    "\n",
    "### La capa de salida\n",
    "\n",
    "Existen **diferentes funciones de activaci√≥n** para clasificaci√≥n y regresi√≥n.\n",
    "\n",
    "### Tipos de funci√≥n de activaci√≥n para la capa de salida\n",
    "\n",
    "- Algunas funciones de activaci√≥n tienen un **rango limitado** (ej: softmax\\sigmoide), mientras que otras se **extienden indefinidamente** (ReLUs, lineal)\n",
    "\n",
    "**Funciones de activaci√≥n para clasificaci√≥n**\n",
    "\n",
    "- Softmax\n",
    "- Sigmoid\n",
    "\n",
    "**Funciones de activaci√≥n para regresi√≥n**\n",
    "\n",
    "- ReLU\n",
    "- Linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√≥mo es el entrenamiento de las redes neuronales\n",
    "\n",
    "Pasos para entrenar una red neuronal\n",
    "1. Escoge tu arquitectura.\n",
    "1. La \"receta\" de entrenamiento.\n",
    "1. Ajustar tu tasa de entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escoge tu arquitectura\n",
    "\n",
    "#### [Deep Feed-Forward (DNNs)](https://es.wikipedia.org/wiki/Red_neuronal_prealimentada)\n",
    "- Funciones de activaci√≥n.\n",
    "- Usada en muchos problemas no lineales complejos.\n",
    " \n",
    "#### [Convolucional (CNNs)](https://es.wikipedia.org/wiki/Red_neuronal_convolucional)\n",
    "- Operador convolucional/pool y kernels.\n",
    "- Usada en im√°genes y gen√≥micos.\n",
    "\n",
    "#### [Recurrente (RNNs)](https://es.wikipedia.org/wiki/Red_neuronal_recurrente)\n",
    "- Celdas de memoria/puerta.\n",
    "- Representa secuencias.\n",
    "- Usada en lenguajes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funci√≥n de perdida (error/coste)\n",
    "\n",
    "#### Error Cuadr√°tico Medio (MSE)\n",
    "\n",
    "Para regresi√≥n.\\\n",
    "Diferencia en valor verdadero versus el predicho.\n",
    "\n",
    "${\\displaystyle \\operatorname {MSE} ={\\frac {1}{n}}\\sum _{i=1}^{n}(Y_{i}-Y_{i,pred})^{2}.}$\n",
    "\n",
    "#### Binary Cross-Entropy (BCE)\n",
    "\n",
    "Para clasificaci√≥n.\\\n",
    "Calcula que tan confiable el modelo predice la probabilidad de una clase para 2 clases\n",
    "\n",
    "\n",
    "$\\displaystyle J= -\\frac{1}{N} \\sum^{N}_{i=1} y_i \\log (p(Class_1)) + (1-y_i) \\log(1-p(Class_1))$\n",
    "\n",
    "#### Categorical Cross-Entropy (CCE)\n",
    "\n",
    "Para **clasificaci√≥n**.\\\n",
    "Similar a BCE, pero para m√°s de 2 etiquetas.\n",
    "\n",
    "$\\displaystyle J = \\sum^{c}_{i=1} -t_1 \\log(p_1)$\\\n",
    "$c \\longrightarrow \\text{number of classes}$\\\n",
    "$a \\longrightarrow \\text{true label}$\\\n",
    "$b \\longrightarrow \\text{probability of predicting label}$\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "Backpropagation es la \"regla de actualizaci√≥n\" usada para ajustar los pesos en redes neuronales.\n",
    "\n",
    "<img src='https://i.stack.imgur.com/1214s.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aprendizaje\n",
    "\n",
    "La optimizaci√≥n se usa para encontrar pesos de acuerdo a las reglas de actualizaci√≥n.\n",
    "\n",
    "- Si la tasa de aprendizaje (learning rate) es **muy peque√±a**, toma mucho tiempo encontrar buenos pesos.\n",
    "- Si es **muy grande**, el modelo podr√≠a atorarse en una mala soluci√≥n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√≥mo mejorar las predicciones de redes neuronales\n",
    "\n",
    "### Dropout protege ante el overfiting\n",
    "\n",
    "Las redes neuronales tienden al overfitting porque tienen muchos par√°metros.\n",
    "\n",
    "<img src='https://www.educative.io/api/edpresso/shot/6668977167138816/image/5033807687188480'>\n",
    "\n",
    "Dropout Aleatoriamente \"ignora\" algunos nodos mientras entrena"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevenir el overfitting\n",
    "\n",
    "<img src=\"https://forum-cdn.knime.com/uploads/default/original/2X/c/c03f5837ac919e7152bdb84b2891d5d0e2674dbf.png\" width=600>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('handling_missing_data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "332e707231cfcd694486fef23a8625039e6ba25634514fa02aad447f735fbe79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
